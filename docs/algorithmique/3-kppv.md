# Algorithme des k plus proches voisins

## Apprentissage automatique (*machine learning *)

L'apprentissage automatique, ou *machine learning* en anglais, est un domaine cl√© de l'intelligence artificielle. Il repose sur des m√©thodes math√©matiques et statistiques qui permettent aux ordinateurs **d'apprendre √† partir de donn√©es** : autrement dit, √† am√©liorer leurs performances dans l'ex√©cution de certaines t√¢ches, sans que chaque √©tape soit explicitement programm√©e.

### Les deux grandes √©tapes de l'apprentissage automatique

1. **Phase d'apprentissage (ou entra√Ænement)** : Le syst√®me analyse un ensemble de donn√©es connues (donn√©es d'entra√Ænement) afin de construire un mod√®le. Ce mod√®le repr√©sente des relations ou des r√®gles apprises √† partir de ces donn√©es.

2. **Phase de mise en production (ou d'inf√©rence)** : Une fois le mod√®le construit, on peut lui soumettre de nouvelles donn√©es pour obtenir une pr√©diction, une classification ou une d√©cision selon la t√¢che cibl√©e.





### üîç Les trois types principaux d'apprentissage automatique

|Type d'apprentissage|Description|Exemples|
|:-|:-|:-|
|üß© Apprentissage supervis√©|Les donn√©es d'entra√Ænement incluent les r√©ponses attendues (¬´ √©tiquettes ¬ª)|Pr√©diction m√©t√©o, reconnaissance d'images|
|üîç Apprentissage non supervis√©|Les donn√©es sont brutes, sans √©tiquettes ; l'algorithme doit trouver des structures cach√©es|Regroupement de clients, segmentation marketing|
|üéÆ Apprentissage par renforcement|Un agent autonome apprend en interagissant avec son environnement ; il re√ßoit des r√©compenses ou p√©nalit√©s|Jeux d'√©checs, optimisation robotique|


L'algorithme des k plus proches voisins (KPPV) (ou KNN pour *k-nearest neighbors*) fait partie de la famille des **apprentissages automatiques supervis√©s**. Il est souvent utilis√© pour r√©soudre des probl√®mes de r√©gression[^3.1] ou de classification[^3.2]. 

[^3.1]: Un probl√®me de r√©gression consiste √† estimer la valeur d'une donn√©e √† partir des valeurs d'autres donn√©es connues,  par exemple pr√©dire le prix d'un bien immobilier selon ses caract√©ristiques.

[^3.2]: Un probl√®me de classification consiste √† d√©terminer √† quelle classe appartient une donn√©e √† partir des classes d'autres donn√©es connues, par exemple d√©terminer √† quelle famille appartient un iris √† partir de la longueur et la largeur des s√©pales et des p√©tales (Iris de Fischer).


Il existe d'autres formes d'apprentissage automatique, par exemple les algorithmes d'apprentissage profond (ou *deep learning*) qui s'appuient sur des r√©seaux de neurones artificiels √† plusieurs couches, d'o√π le nom ¬´ profond ¬ª, tels que les grands mod√®les de langages (ou LLLM pour *large language models*) : ChatGPT, Gemini, Mistral, etc.


## Principe des KPPV


!!! abstract "Cours" 
    L'algorithme des k plus proches voisins (KPPV) ou *k-nearest neigbors* (KNN) pr√©dit la valeur ou la classe d'une nouvelle donn√©e √† partir des k plus proches donn√©es parmi des donn√©es d'entra√Ænement. La proximit√© est souvent mesur√©e √† l'aide de la **distance euclidienne**[^3.3].

[^3.3]: D'autres distances existent, par exemple la distance de Manhattan calcul√©e en utilisant les d√©placements horizontaux et verticaux.

Prenons un exemple simple simple de classification : On dispose de 6 donn√©es d'entra√Ænement identifi√©es par des valeurs x et y et appartenant √† deux classes: des carr√©s bleus et des triangles rouges. On peut repr√©senter ces donn√©es dans un plan :

![Donn√©es d'apprentissage contenant 3 triangles rouges et 3 carr√©s bleus](assets/3-kppv-donnees-d-apprentissage.png){width=45% align=right}


|(x, y)|Classe|
|:-:|:-|
| (1, 2) |Carr√© bleu|
| (2, 5) |Triangle rouge|
| (4, 1) |Carr√© bleu|
| (5, 4) |Triangle rouge|
| (6, 2) |Carr√© bleu|
| (6, 6) |Triangle rouge|

On cherche maintenant √† d√©terminer la classe d'une nouvelle donn√©e, de valeur x = 4 et y = 3. Est-ce que cette nouvelle donn√©e est un carr√© bleu ou triangle rouge ?  Pour l'instant on la repr√©sente dans le plan par une √©toile verte.

üîç √âtape 1 : calcul des distances

La distance euclidienne entre deux points de coordonn√©es $(x_1, y_1)$ et $(x_2,y_2)$ est donn√©e par la formule :  $d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$ [^3.4].

Calculons les distances entre les donn√©es d'entra√Ænement et la nouvelle donn√©e :

[^3.4]: Dans un rep√®re orthnorm√©.

![Calcul des distances](assets/3-kppv-calcul-des-distances-2.png){width=45% align=right}

|(x,y)|Classe|Distance de (4, 3)|
|:-:|:-|:-:|
| (1, 2) |Carr√© bleu|3.2|
| (2, 5) |Triangle rouge|2.8|
| (4, 1) |Carr√© bleu|2.0|
| (5, 4) |Triangle rouge|1.4|
| (6, 2) |Carr√© bleu|2.2|
| (6, 6) |Triangle rouge|3.6|



üé® √âtape 2 : vote des k voisins

![Classement avec les 3 plus proches voisins](assets/3-kppv-choix-k-1-3.png){width=45% align=right}

L'approche la plus simple consiste √† utiliser la classe du voisin le plus proche, c'est-√†-dire prendre k = 1. C'est la donn√©e d'entra√Ænement en (5, 4) qui se trouve √† une distance de 1.4 de la nouvelle donn√©e: c'est un triangle rouge. üëâ On en d√©duit que la nouvelle donn√©e de valeurs (4, 3) est de la m√™me classe, c'est donc un ¬´ triangle rouge ¬ª.


Une autre approche consiste √† prendre compte plusieurs voisins, par exemple 3 voisins, c'est-√†-dire prendre k = 3. Les 3 donn√©es d'entra√Ænement les plus proches sont : 

- (4, 5) ‚Üí Triangle rouge

- (4, 1) ‚Üí Carr√© bleu

- (6, 2) ‚Üí Carr√© bleu


Parmi ces 3 voisins, non trouve donc 2 carr√©s bleus contre 1 seul triangle rouge.  üëâ On en d√©duit que la nouvelle donn√©e de valeurs (4, 3) est un carr√© bleu.

Comme on peut le voir, le choix de la valeur de k utilis√©e dans l'algorithme est d√©terminant sur le r√©sultat obtenu ! 

Note: On choisit en principe une valeur impaire de k pour √©viter les cas d'√©galit√© entre plusieurs classes.



!!! question "Exercice corrig√©" 
    Le jeu de donn√©es Iris connu aussi sous le nom de Iris de Fisher est un jeu de donn√©es multivari√©es pr√©sent√© en 1936 par Ronald Fisher dans son papier ¬´¬†The use of multiple measurements in taxonomic problems¬†¬ª comme un exemple d'application de l'analyse discriminante lin√©aire. [‚Ä¶]

    Le jeu de donn√©es comprend 50 √©chantillons de chacune des trois esp√®ces d'iris (Iris setosa, Iris virginica et Iris versicolor).  Quatre caract√©ristiques ont √©t√© mesur√©es √† partir de chaque √©chantillon : la longueur et la largeur des s√©pales et des p√©tales, en centim√®tres. Sur la base de la combinaison de ces quatre variables, Fisher a √©labor√© un mod√®le d'analyse discriminante lin√©aire permettant de distinguer les esp√®ces les unes des autres.

    ||||
    |:-:|:-:|:-:|
    |![Iris setosa](assets/500px-Kosaciec_szczecinkowaty_Iris_setosa.jpg)Iris setosa|![Iris versicolor](assets/960px-Iris_versicolor_3.jpg)Iris versicolor|![Iris setosa](assets/960px-Iris_virginica.jpg)Iris virginica|
  
    Bas√© sur le mod√®le d'analyse lin√©aire discriminante de Fisher, ce jeu de donn√©es est devenu un cas typique pour de nombreuses techniques de classification automatique en apprentissage automatique (*machine learning*).

    Source¬†: [https://fr.wikipedia.org/wiki/Iris_de_Fisher](https://fr.wikipedia.org/wiki/Iris_de_Fisher)

    1.  Copier le fichier [¬´¬†iris.csv¬†¬ª](assets/iris.csv) dans vos documents et visualiser avec le blocnote son contenu. Quel est le caract√®re utilis√© pour s√©parer les donn√©es dans le fichier ? Quels sont les descripteurs¬†des donn√©es ?

    2.  Cr√©er un nouveau programme Python enregistr√© dans le m√™me r√©pertoire que le fichier "iris.csv" puis importer les donn√©es contenues dans le fichier avec le code suivant en renseignant le caract√®re de s√©paration des donn√©es (param√®tre `delimiter`) :

        ``` py
        import csv

        with open('iris.csv', 'r') as f:
            iris = list(csv.DictReader(f, delimiter='...')
        ```

    3.  Quel est le type Python de la variable `iris` ?

        a) un dictionnaire		b) un dictionnaire de tableaux	c) un tableau de dictionnaires	d) un tableau de tableaux

    4.  Ajouter au programmme une fonction `distance_euclidienne` qui prend en param√®tre `iris1` et `iris2`, deux √©l√©ments de la variable `iris`, et qui renvoie la distance euclidienne entre les valeurs `('largeur_petale', 'longueur_petale')`. 

        Aide¬†: la fonction `sqrt` du module `math` renvoie la racine carr√©e d'un nombre. 
        
        Attention au type de `'largeur_petale'` et `'longueur_petale'`¬†! 

        Exemple¬†: 
        ``` py
        >>> distance_euclidienne(iris[0], iris[3])
        0.10000000000000009
        ```

    5.  √âcrire une fonction `trier_par_distance` qui prend en param√®tre¬†`inconnu`, un dictionnaire dont les cl√©s sont 'largeur_petale' et 'longueur_petale' et les valeurs celles d'un iris inconnu, et renvoie un tableau de dictionnaires avec les cl√©s `'id'`, `'distance'` et `'espece'` pour chaque iris de la variable `iris`, tri√©s par distances croissantes.

        Aide¬†: L'instruction `distances.sort(key=lambda x: x["distance"])` permet de trier le tableau de dictionnaires `distances` contenant une cl√© `"distance"` par ordre croissant de cette cl√©. 

        Exemple¬†: 
        ``` py
        >>> iris_inconnnu = {'largeur_petale': '0.3', 'longueur_petale': '2.1',}
        >>> trier_par_distance(iris_inconnnu)
        [[{'id': '61', 'distance': 0.7, 'espece': 'Iris-versicolor'}, {'id': '80', 'distance': 0.7, 'espece': 'Iris-versicolor'}, {'id': '58', 'distance': 0.7280109889280518, 'espece': 'Iris-versicolor'}...
        ```

    6.  √âcrire la fonction `kppv` qui prend en param√®tres¬†:
        - `inconnu`, un dictionnaire contenant un iris inconnu
        - `k` un entier
        et renvoie un dictionnaire contenant le nombre d'iris de chaque esp√®ce parmi les k plus proches voisins de l'iris inconnu.

        Exemple¬†:
        ``` py
        >>> kppv(iris_inconnnu, k=9)
        {'Iris-setosa': 0, 'Iris-versicolor': 9, 'Iris-virginica': 0}
        ```

        


    

??? Success "R√©ponse"
    1.  Les valeurs sont s√©par√©es par des  virgules , les descripteurs sont¬†: id,longueur_sepale, largeur_sepale, longueur_petale, largeur_petale, espece.

    2.  

        ``` py
        import csv

        with open('iris.csv', 'r') as f:
            iris = list(csv.DictReader(f, delimiter=',')
        ```

    3.  un tableau de dictionnaires

    4.  

        ``` py
        from math import sqrt

        def distance_euclidienne(iris1, iris2):
            x1, y1 = float(iris1['largeur_petale']), float(iris1['longueur_petale'])
            x2, y2 = float(iris2['largeur_petale']), float(iris2['longueur_petale'])
            return sqrt((x2 - x1)**2 + (y2 ‚Äì y1)**2))
        ```
    
    5.  

        ``` py
        def trier_par_distance(inconnu):
            """ dict -> list[dict]
            Renvoie un tableau de dictionnaires {'id':_, 'distance':_, 'espece':_}
            pour chaque iris d'entrainement, tri√©s par distance d√©croissantes
            """
            distances = []
            for i in iris:
                distances.append({'id': i['id'],
                                  'distance': distance_euclidienne(i, inconnu),
                                  'espece':  i['espece']})
            distances.sort(key=lambda x: x["distance"])
            return distances
        ```

    6.  

        ``` py
        def kppv(inconnu, k):
            """ dict, int -> dict
            Renvoie un dictionnaire contenant le nombre d'iris de chaque esp√®ce 
            parmi les k plus proches voisins de l'iris inconnu 
            """
            especes = {'Iris-setosa':0, 'Iris-versicolor':0, 'Iris-virginica':0}
            plus_proches = trier_par_distance(inconnu)[:k]
            for pp in plus_proches:
                especes[pp['espece']] += 1
            return especes
        ```


