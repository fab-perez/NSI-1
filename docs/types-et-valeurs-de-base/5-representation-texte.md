# ReprÃ©sentation dâ€™un texte en machine

Un ordinateur ne manipule que des nombres binaires (0 et 1), alors comment fait-il pour reprÃ©senter du texte, les lettres, les chiffres et autres symboles que l'on utilise ? C'est ce qu'on appelle l'**encodage**.

!!! abstract "Cours" 
    Un **systÃ¨me d'encodage** Ã©tablit une **correspondance entre des caractÃ¨res (lettres, chiffres, ponctuation) et des nombres**. Chaque caractÃ¨re se voit attribuer un code numÃ©rique unique, que l'ordinateur peut stocker et manipuler.

## L'encodage ASCII

!!! abstract "Cours" 
    CrÃ©Ã© dans les annÃ©es 60, l'ASCII (*American Standard Code for Information Interchange*) est la base de presque tous les encodages actuels. Il utilise 7 bits pour coder chaque caractÃ¨re, ce qui permet de reprÃ©senter $2^7 = 128$ caractÃ¨res : 

    - Les chiffres 0 Ã  9 (de 48 Ã  57).
    - Les lettres majuscules A Ã  Z (de 65 Ã  90)
    - Les lettres minuscules a Ã  z (de 97 Ã  122).
    - Les signes de ponctuation courants.
    - Des caractÃ¨res spÃ©ciaux (tabulation, nouvelle ligne, etc.) et des caractÃ¨res de contrÃ´le non imprimables pour des protocole de communication et des contrÃ´les de pÃ©riphÃ©riques (Fin de transmission, etc. ).

Le tableau suivant montre lâ€™encodage des 128 caractÃ¨res ASCII :
![Table des 128 caractÃ¨res ASCII](assets/5-ascii-table.png){width=100%}



L'ASCII fonctionne trÃ¨s bien pour l'anglais, mais il ne contient aucun caractÃ¨re accentuÃ© (Ã©, Ã¨, Ã , Ã§, etc.), aucun symbole spÃ©cifique Ã  d'autres langues, et encore moins de caractÃ¨res d'alphabets non latins (cyrillique, arabe, chinois, etc.).


## L'encodage ISO-8859-1 (Latin-1)

!!! abstract "Cours" 
    Pour rÃ©soudre le problÃ¨me des accents, ISO-8859-1, aussi appelÃ© Latin-1, utilise 8 bits par caractÃ¨re, permettant de coder $2^8 = 256$ caractÃ¨res :

    - Les 128 premiers caractÃ¨res (0 Ã  127) sont identiques Ã  l'ASCII.
    - Les 128 caractÃ¨res suivants (128 Ã  255) ajoutent les caractÃ¨res accentuÃ©s et symboles nÃ©cessaires aux langues d'Europe occidentale (franÃ§ais, espagnol, allemand, etc.). On y trouve : Ã©, Ã¨, Ãª, Ã«, Ã , Ã¹, Ã§, Ã±, Ã¶, etc.

Le tableau suivant[^5.1] montre lâ€™encodage des 256 caractÃ¨res ISO-8859-1. Les titres des lignes et des colonnes indiquent les valeurs hexadÃ©cimales correspondant aux positions codÃ©es assignÃ©es Ã  chaque caractÃ¨re, par exemple, la valeur hexadÃ©cimale de la position codÃ©e assignÃ©e Ã  la lettre Â« L Â» est $4C_{16}$, soit 01001100 en binaire ou 76 en dÃ©cimal.

[^5.1]: source: [https://fr.wikipedia.org/wiki/ISO/CEI_8859-1](https://fr.wikipedia.org/wiki/ISO/CEI_8859-1)

![Table des 256 caractÃ¨res ISO-8859-1](assets/5-iso-8859-1-table.png){width=70%}


Si l'ISO-8859-1 est une amÃ©lioration de l'encodage ASCII, il ignore encore quelques caractÃ¨res europÃ©ens comme le symbole de lâ€™euro â‚¬ (qui nâ€™existait pas encore lorsque ce jeu a Ã©tÃ© normalisÃ©) ou certaines des lettres normalement nÃ©cessaires Ã  certaines langues thÃ©oriquement couvertes (comme les lettres Â« Å“ Â», Â« Å’ Â» et Â« Å¸ Â» en franÃ§ais, ou les lettres Â« Å¡ Â» et Â« Å  Â» en finnois).

Par ailleurs, bien qu'utile pour l'Europe occidentale, ISO-8859-1 ne peut pas reprÃ©senter les caractÃ¨res d'autres rÃ©gions du monde. Il existe d'autres variantes (ISO-8859-2 pour l'Europe centrale, ISO-8859-5 pour le cyrillique, etc.), mais on ne peut pas mÃ©langer plusieurs alphabets dans un mÃªme document.



## Le standard universel : Unicode et UTF-8

Face Ã  la multiplication des systÃ¨mes d'encodage incompatibles entre eux, le consortium Unicode a crÃ©Ã© un rÃ©pertoire universel de caractÃ¨res. L'objectif : attribuer un numÃ©ro unique (appelÃ© "**point de code**") Ã  chaque caractÃ¨re de chaque langue. Unicode contient actuellement plus de 140 000 caractÃ¨res, incluant :

- Tous les alphabets (latin, cyrillique, arabe, hÃ©breu, grec., etc.).
- Les idÃ©ogrammes chinois, japonais et corÃ©ens.
- Les Ã©mojis.
- Des symboles mathÃ©matiques, musicaux, etc.

Chaque point de code s'Ã©crit sous la forme U+xxxx oÃ¹ chaque chiffre x est un caractÃ¨re hexadÃ©cimal avec au moins quatre chiffres. Les points de code vont de U+0000 Ã  U+10FFFF. 


En Python, la fonction `ord` renvoie le code Unicode d'un caractÃ¨re en dÃ©cimal :

``` python
>>> ord('Ã©')
233
>>> ord('â‚¬')
8364
```

et inversement, la fonction `chr` renvoie le caractÃ¨re d'un point de code :

``` python
>>> chr(233)
'Ã©'
>>> chr(0xE9)
'Ã©'
>>> chr(0x1F60B)
'ðŸ˜‹'
```

Les opÃ©rateurs de comparaison entre caractÃ¨res `==`, `<` et `>` comparent les points de code dans l'ordre lexicographique (ou Â« ordre du dictionnaire Â»).

``` python
>>> 'a' < 'A'
False
>>> '12' < '2'
True
>>> chr(0x1F600)
'ðŸ˜€'
>>> chr(0x1F602)
'ðŸ˜‚'
>>> 'ðŸ˜€' < 'ðŸ˜‚'
True
``` 



En sÃ©parant le point de code (le sens) de l'encodage (le stockage), Unicode permet de reprÃ©senter tous les systÃ¨mes d'Ã©criture du monde dans un seul standard. Il existe plusieurs encodages pour la table Unicode :

- UTF-32 : Utilise toujours 4 octets. Simple mais prend beaucoup de place.

- UTF-16 : Utilise gÃ©nÃ©ralement 2 octets (parfois 4). UtilisÃ© par Windows et Java en interne.

- UTF-8 : Utilise un nombre variable d'octets (1 Ã  4). C'est le plus courant sur le web.


Prenons l'exemple du caractÃ¨re "Ã©". Son point de code est U+00E9.

L'encodage UTF-32 est la traduction directe du point de code sur 4 octets : 00 00 00 E9 en hexadÃ©cimal ou encore 00000000 00000000 00000000 11101001 en binaire.

L'encodage UTF-8 ne nÃ©cessite que 2 octets  : C3 A9 en hexadÃ©cimal ou 11000011 10101001 en binaire (l'encodage UTF-8 est expliquÃ© en exercice).

Le mot Â«Â mÃ©tÃ©oÂ Â»  est donc encodÃ© en UTF-8 par `6D C3 A9 74 C3 A9 6F` :

- `6D` pour Â«Â mÂ Â»  
- `C3 A9` pour Â«Â Ã© Â» 
- `74` pour Â«Â t Â»  
- `C3 A9` pour Â«Â Ã© Â» 
- `6F` pour Â«Â o Â»  

donc avec seulement 7 octets pour 5 caractÃ¨res, ce qui est bien moins que les 20 octets en UTF-32 !


Notez qu'un logiciel lisant cet encodage en format ISO-8859-1 affichera  Â«Â mÃƒÂ©tÃƒÂ©oÂ Â» au lieu de Â«Â mÃ©tÃ©oÂ Â», car `C3` encode la lettre Â«Â Ãƒ Â»  et `A9` la lettre Â«Â Â© Â» en ISO-8859-1. C'est Ã  l'origine de la majoritÃ© des bugs d'affichage de caractÃ¨res accentuÃ©s sur Internet !

Un autre avantage d'UTF-8 est de permettre d'utiliser tous les caractÃ¨res, symboles, emojis, etc. en mÃªme temps. Par exemple, texte "Hello ä½ å¥½" (anglais + chinois) peut Ãªtre reprÃ©sentÃ© dans le mÃªme fichier, ce qui Ã©tait impossible avec ASCII ou ISO-8859-1.


!!! abstract "Cours" 
    **UTF-8** (*Unicode Transformation Format - 8 bits*) est l'**encodage Unicode le plus  rÃ©pandu**. Il sâ€™agit dâ€™un encodage Ã  longueur variable car chaque caractÃ¨re est encodÃ© **sur 1, 2, 3 ou 4 octets** :

    - Les caractÃ¨res ASCII (les plus courants) sont codÃ©s sur 1 octet.
    - Les caractÃ¨res accentuÃ©s europÃ©ens utilisent 2 octets.
    - De nombreux autres caractÃ¨res (emojis, symboles) utilisent 3 ou 4 octets.


UTF-8 offre de nombreux avantages :

1.  CompatibilitÃ© avec ASCII : tout fichier ASCII valide est aussi un fichier UTF-8 valide.
2.  UniversalitÃ© : on peut mÃ©langer tous les alphabets dans un mÃªme document.
3.  EfficacitÃ© : les textes en langues occidentales restent compacts car les caractÃ¨res courants utilisent peu d'octets.
4.  Standard : C'est le standard du Web aujourd'hui. 

C'est l'encodage qu'il est actuellement recommandÃ© d'utiliser.


## Comparaisons


!!! abstract "Cours" 

    |CritÃ¨re|ASCII|ISO-8859-1|UTF-8|
    |:-|:-|:-|:-|
    |Nombre de caractÃ¨res|128|256|Plus de 140 000|
    |Taille par caractÃ¨re|7 bits|1 octet fixe|1 Ã  4 octets variable|
    |Langues supportÃ©es|Anglais|Europe occidentale|Toutes|
    |Avantage|TrÃ¨s lÃ©ger|GÃ¨re le franÃ§ais|Universel|
    |Inconvenient|Pas d'accents|Incompatible avec le reste du monde|Fichiers parfois plus lourds|
    |Usage actuel|LimitÃ©|DÃ©croissant|Standard du web|




## Convertir un texte dans diffÃ©rents formats dâ€™encodage

MÃªme si UTF-8 est devenu le standard, on rencontre encore d'autres encodages pour des raisons historiques. Certains anciens systÃ¨mes ou fichiers utilisent toujours ISO-8859-1 ou d'autres encodages. Et quand on ouvre un fichier encodÃ© dans un certain format en utilisant un dÃ©codeur diffÃ©rent, on obtient des caractÃ¨res Ã©tranges Ã  l'Ã©cran (ex: ÃƒÂ© au lieu de Ã©).

Une mÃªme suite de bits peut Ãªtre interprÃ©tÃ©e diffÃ©remment selon l'encodage choisi. Il est donc important de savoir identifier et convertir entre diffÃ©rents formats. 


Les mÃ©thodes Python `encode` et `decode` transforment une chaÃ®ne de caractÃ¨res (type `str`) en une suite d'octets (`bytes`) et rÃ©ciproquement (les caractÃ¨res ASCII sont encodÃ©s tels quels). Elles permettent de passer d'un encodage Ã  l'autre  :

``` python
>>> "m".encode()
b'm'
>>> "Ã©".encode("utf-8")
b'\xc3\xa9'
>>> "Ã©".encode("iso-8859-1")
b'\xe9'
>>> b'\xc3\xa9'.decode("utf-8")
'Ã©'
>>> b'\xc3\xa9'.decode("iso-8859-1")       # le bug classique d'un encodage utf-8 lu en latin-1 !
'ÃƒÂ©'
```

Quand on travaille avec des fichiers textes, il faut toujours spÃ©cifier l'encodage lors de la lecture ou l'Ã©criture. Par exemple, on peut lire le texte d'un fichier au format ISO-8859-1 :

```Python
# Lire le fichier en ISO-8859-1
with open('fichier.txt', 'r', encoding='iso-8859-1') as f:
    texte = f.read()
```   
Cela permet de convertir un fichier d'un encodage Ã  un autre facilement, par exemple pour enregistrer le fichier prÃ©cÃ©dant au format UTF-8, on ajoute au code : 


```Python
# Sauvegarder en UTF-8
with open('fichier_utf8.txt', 'w', encoding='utf-8') as f:
    f.write(texte)
```





