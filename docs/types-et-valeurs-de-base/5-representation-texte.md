# Repr√©sentation d‚Äôun texte en machine

Un ordinateur ne manipule que des nombres binaires (0 et 1), alors comment fait-il pour repr√©senter du texte, les lettres, les chiffres et autres symboles que l'on utilise ? C'est ce qu'on appelle l'**encodage**.

!!! abstract "Cours" 
    Un **syst√®me d'encodage** √©tablit une **correspondance entre des caract√®res (lettres, chiffres, ponctuation) et des nombres**. Chaque caract√®re se voit attribuer un code num√©rique unique, que l'ordinateur peut stocker et manipuler.

## L'encodage ASCII

!!! abstract "Cours" 
    Cr√©√© dans les ann√©es 60, l'ASCII (*American Standard Code for Information Interchange*) est la base de presque tous les encodages actuels. Il utilise 7 bits pour coder chaque caract√®re, ce qui permet de repr√©senter $2^7 = 128$ caract√®res : 

    - Les chiffres 0 √† 9 (de 48 √† 57).
    - Les lettres majuscules A √† Z (de 65 √† 90)
    - Les lettres minuscules a √† z (de 97 √† 122).
    - Les signes de ponctuation courants.
    - Des caract√®res sp√©ciaux (tabulation, nouvelle ligne, etc.) et des caract√®res de contr√¥le non imprimables pour des protocole de communication et des contr√¥les de p√©riph√©riques (Fin de transmission, etc. ).

Le tableau suivant montre l‚Äôencodage des 128 caract√®res ASCII :
![Table des 128 caract√®res ASCII](assets/5-ascii-table.png){width=100%}



L'ASCII fonctionne tr√®s bien pour l'anglais, mais il ne contient aucun caract√®re accentu√© (√©, √®, √†, √ß, etc.), aucun symbole sp√©cifique √† d'autres langues, et encore moins de caract√®res d'alphabets non latins (cyrillique, arabe, chinois, etc.).


## L'encodage ISO-8859-1 (Latin-1)

!!! abstract "Cours" 
    Pour r√©soudre le probl√®me des accents, ISO-8859-1, aussi appel√© Latin-1, utilise 8 bits par caract√®re, permettant de coder $2^8 = 256$ caract√®res :

    - Les 128 premiers caract√®res (0 √† 127) sont identiques √† l'ASCII.
    - Les 128 caract√®res suivants (128 √† 255) ajoutent les caract√®res accentu√©s et symboles n√©cessaires aux langues d'Europe occidentale (fran√ßais, espagnol, allemand, etc.). On y trouve : √©, √®, √™, √´, √†, √π, √ß, √±, √∂, etc.

Le tableau suivant[^5.1] montre l‚Äôencodage des 256 caract√®res ISO-8859-1. Les titres des lignes et des colonnes indiquent les valeurs hexad√©cimales correspondant aux positions cod√©es assign√©es √† chaque caract√®re, par exemple, la valeur hexad√©cimale de la position cod√©e assign√©e √† la lettre ¬´ L ¬ª est $4C_{16}$, soit 01001100 en binaire ou 76 en d√©cimal.

[^5.1]: source: [https://fr.wikipedia.org/wiki/ISO/CEI_8859-1](https://fr.wikipedia.org/wiki/ISO/CEI_8859-1)

![Table des 256 caract√®res ISO-8859-1](assets/5-iso-8859-1-table.png){width=70%}


Si l'ISO-8859-1 est une am√©lioration de l'encodage ASCII, il ignore encore quelques caract√®res europ√©ens comme le symbole de l‚Äôeuro ‚Ç¨ (qui n‚Äôexistait pas encore lorsque ce jeu a √©t√© normalis√©) ou certaines des lettres normalement n√©cessaires √† certaines langues th√©oriquement couvertes (comme les lettres ¬´ ≈ì ¬ª, ¬´ ≈í ¬ª et ¬´ ≈∏ ¬ª en fran√ßais, ou les lettres ¬´ ≈° ¬ª et ¬´ ≈† ¬ª en finnois).

Par ailleurs, bien qu'utile pour l'Europe occidentale, ISO-8859-1 ne peut pas repr√©senter les caract√®res d'autres r√©gions du monde. Il existe d'autres variantes (ISO-8859-2 pour l'Europe centrale, ISO-8859-5 pour le cyrillique, etc.), mais on ne peut pas m√©langer plusieurs alphabets dans un m√™me document.



## Le standard universel : Unicode et UTF-8

Face √† la multiplication des syst√®mes d'encodage incompatibles entre eux, le consortium Unicode a cr√©√© un r√©pertoire universel de caract√®res. L'objectif : attribuer un num√©ro unique (appel√© "**point de code**") √† chaque caract√®re de chaque langue. Unicode contient actuellement plus de 140 000 caract√®res, incluant :

- Tous les alphabets (latin, cyrillique, arabe, h√©breu, grec., etc.).
- Les id√©ogrammes chinois, japonais et cor√©ens.
- Les √©mojis.
- Des symboles math√©matiques, musicaux, etc.

Chaque point de code s'√©crit sous la forme U+xxxx o√π chaque chiffre x est un caract√®re hexad√©cimal avec au moins quatre chiffres. Les points de code vont de U+0000 √† U+10FFFF. 


En Python, la fonction `ord` renvoie le code Unicode d'un caract√®re en d√©cimal :

``` python
>>> ord('√©')
233
>>> ord('‚Ç¨')
8364
```

et inversement, la fonction `chr` renvoie le caract√®re d'un point de code :

``` python
>>> chr(233)
'√©'
>>> chr(0xE9)
'√©'
>>> chr(0x1F60B)
'üòã'
```

Les op√©rateurs de comparaison entre caract√®res `==`, `<` et `>` comparent les points de code dans l'ordre lexicographique (ou ¬´ ordre du dictionnaire ¬ª).

``` python
>>> 'a' < 'A'
False
>>> '12' < '2'
True
``` 



En s√©parant le point de code (le sens) de l'encodage (le stockage), Unicode permet de repr√©senter tous les syst√®mes d'√©criture du monde dans un seul standard. Il existe plusieurs encodages pour la table Unicode :

- UTF-32 : Utilise toujours 4 octets. Simple mais prend beaucoup de place.

- UTF-16 : Utilise g√©n√©ralement 2 octets (parfois 4). Utilis√© par Windows et Java en interne.

- UTF-8 : Utilise un nombre variable d'octets (1 √† 4). C'est le plus courant sur le web.


Prenons l'exemple du caract√®re "√©". Son point de code est U+00E9.

L'encodage UTF-32 est la traduction directe du point de code sur 4 octets : 00 00 00 E9 en hexad√©cimal ou encore 00000000 00000000 00000000 11101001 en binaire.

L'encodage UTF-8 ne n√©cessite que 2 octets  : C3 A9 en hexad√©cimal ou 11000011 10101001 en binaire (l'encodage UTF-8 est expliqu√© en exercice).

Le mot ¬´¬†m√©t√©o¬†¬ª  est donc encod√© en UTF-8 par `6D C3 A9 74 C3 A9 6F` :

- `6D` pour ¬´¬†m¬†¬ª  
- `C3 A9` pour ¬´¬†√© ¬ª 
- `74` pour ¬´¬†t ¬ª  
- `C3 A9` pour ¬´¬†√© ¬ª 
- `6F` pour ¬´¬†o ¬ª  

donc avec seulement 7 octets pour 5 caract√®res, ce qui est bien moins que les 20 octets en UTF-32 !


Notez qu'un logiciel lisant cet encodage en format ISO-8859-1 affichera  ¬´¬†m√É¬©t√É¬©o¬†¬ª au lieu de ¬´¬†m√©t√©o¬†¬ª, car `C3` encode la lettre ¬´¬†√É ¬ª  et `A9` la lettre ¬´¬†¬© ¬ª en ISO-8859-1. C'est √† l'origine de la majorit√© des bugs d'affichage de caract√®res accentu√©s sur Internet !

Un autre avantage d'UTF-8 est de permettre d'utiliser tous les caract√®res, symboles, emojis, etc. en m√™me temps. Par exemple, texte "Hello ‰Ω†Â•Ω" (anglais + chinois) peut √™tre repr√©sent√© dans le m√™me fichier, ce qui √©tait impossible avec ASCII ou ISO-8859-1.


!!! abstract "Cours" 
    **UTF-8** (*Unicode Transformation Format - 8 bits*) est l'**encodage Unicode le plus  r√©pandu**. Il s‚Äôagit d‚Äôun encodage √† longueur variable car chaque caract√®re est encod√© **sur 1, 2, 3 ou 4 octets** :

    - Les caract√®res ASCII (les plus courants) sont cod√©s sur 1 octet.
    - Les caract√®res accentu√©s europ√©ens utilisent 2 octets.
    - De nombreux autres caract√®res (emojis, symboles) utilisent 3 ou 4 octets.


UTF-8 offre de nombreux avantages :

1.  Compatibilit√© avec ASCII : tout fichier ASCII valide est aussi un fichier UTF-8 valide.
2.  Universalit√© : on peut m√©langer tous les alphabets dans un m√™me document.
3.  Efficacit√© : les textes en langues occidentales restent compacts car les caract√®res courants utilisent peu d'octets.
4.  Standard : C'est le standard du Web aujourd'hui. 

C'est l'encodage qu'il est actuellement recommand√© d'utiliser.


## Comparaisons


!!! abstract "Cours" 

    |Crit√®re|ASCII|ISO-8859-1|UTF-8|
    |:-|:-|:-|:-|
    |Nombre de caract√®res|128|256|Plus de 140 000|
    |Taille par caract√®re|7 bits|1 octet fixe|1 √† 4 octets variable|
    |Langues support√©es|Anglais|Europe occidentale|Toutes|
    |Avantage|Tr√®s l√©ger|G√®re le fran√ßais|Universel|
    |Inconvenient|Pas d'accents|Incompatible avec le reste du monde|Fichiers parfois plus lourds|
    |Usage actuel|Limit√©|D√©croissant|Standard du web|




## Convertir un texte dans diff√©rents formats d‚Äôencodage

M√™me si UTF-8 est devenu le standard, on rencontre encore d'autres encodages pour des raisons historiques. Certains anciens syst√®mes ou fichiers utilisent toujours ISO-8859-1 ou d'autres encodages. Et quand on ouvre un fichier encod√© dans un certain format en utilisant un d√©codeur diff√©rent, on obtient des caract√®res √©tranges √† l'√©cran (ex: √É¬© au lieu de √©).

Une m√™me suite de bits peut √™tre interpr√©t√©e diff√©remment selon l'encodage choisi. Il est donc important de savoir identifier et convertir entre diff√©rents formats. 


Les m√©thodes Python `encode` et `decode` transforment une cha√Æne de caract√®res (type `str`) en une suite d'octets (`bytes`) et r√©ciproquement (les caract√®res ASCII sont encod√©s tels quels). Elles permettent de passer d'un encodage √† l'autre  :

``` python
>>> "m".encode()
b'm'
>>> "√©".encode("utf-8")
b'\xc3\xa9'
>>> "√©".encode("iso-8859-1")
b'\xe9'
>>> b'\xc3\xa9'.decode("utf-8")
'√©'
>>> b'\xc3\xa9'.decode("iso-8859-1")       # le bug classique d'un encodage utf-8 lu en latin-1 !
'√É¬©'
```

Quand on travaille avec des fichiers textes, il faut toujours sp√©cifier l'encodage lors de la lecture ou l'√©criture. Par exemple, on peut lire le texte d'un fichier au format ISO-8859-1 :

```Python
# Lire le fichier en ISO-8859-1
with open('fichier.txt', 'r', encoding='iso-8859-1') as f:
    texte = f.read()
```   
Cela permet de convertir un fichier d'un encodage √† un autre facilement, par exemple pour enregistrer le fichier pr√©c√©dant au format UTF-8, on ajoute au code : 


```Python
# Sauvegarder en UTF-8
with open('fichier_utf8.txt', 'w', encoding='utf-8') as f:
    f.write(texte)
```





